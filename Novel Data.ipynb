{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1061229f",
   "metadata": {},
   "source": [
    "# Novel Data: Training PFENet\n",
    "\n",
    "For a description of how the [PFENet](https://github.com/dvlab-research/PFENet) works, please refer to [Understanding PFENet](./Understanding%20PFENet.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f088d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from util import dataset\n",
    "from util import transform\n",
    "\n",
    "def render(img):\n",
    "    I = np.array(img)\n",
    "    I = I - I.min((1,2), keepdims=1)\n",
    "    I = I / I.max((1,2), keepdims=1)\n",
    "    I = I.transpose((1,2, 0))\n",
    "    return I\n",
    "    \n",
    "def overlay(img, mask, chan=1, weights=[0.5, 0.5]):\n",
    "    T = np.zeros_like(img)\n",
    "    T[..., chan] = mask\n",
    "    return img * weights[0] + T * weights[1]\n",
    "\n",
    "def val_transform(img, label, __cache={}):\n",
    "    if not __cache:\n",
    "        value_scale = 255\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        mean = [item * value_scale for item in mean]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        std = [item * value_scale for item in std]\n",
    "        __cache['val_transform'] = transform.Compose([\n",
    "            transform.test_Resize(size=473),\n",
    "            transform.ToTensor(),\n",
    "            transform.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "    f = __cache['val_transform']\n",
    "    return f(img, label)\n",
    "\n",
    "def fetch_ivus_triplet(fi, fm, fl):\n",
    "    with open(fl) as f:\n",
    "        pts_lum = np.array([\n",
    "            list(map(float, line.strip().split(',')))\n",
    "            for line in f.readlines()\n",
    "        ], np.int32)\n",
    "        pts_lum = pts_lum.reshape((-1, 1, 2))\n",
    "\n",
    "    with open(fm) as f:\n",
    "        pts_med = np.array([\n",
    "            list(map(float, line.strip().split(',')))\n",
    "            for line in f.readlines()\n",
    "        ], np.int32)\n",
    "        pts_med = pts_med.reshape((-1, 1, 2))\n",
    "    \n",
    "    img = cv2.imread(fi, cv2.IMREAD_COLOR)\n",
    "    img = img[..., [0, 0, 0]]\n",
    "    \n",
    "\n",
    "    # Inside of lumen\n",
    "    lab_lumen = np.zeros(img.shape[:-1])\n",
    "    cv2.fillPoly(lab_lumen, [pts_lum], 1)\n",
    "    \n",
    "    # Inside of media\n",
    "    lab_media = np.zeros_like(lab_lumen)\n",
    "    cv2.fillPoly(lab_media, [pts_med], 1)\n",
    "    #lab_media -= lab_lumen # remove points in lumen\n",
    "    \n",
    "    # Border of lumen\n",
    "    lab_lumen = cv2.polylines(lab_lumen, [pts_lum], True, 255, 2)\n",
    "    \n",
    "    # Border of media\n",
    "    #lab_media = cv2.polylines(lab_media, [pts_lum], True, 255, 2)\n",
    "    lab_media = cv2.polylines(lab_media, [pts_med], True, 255, 2)\n",
    "    \n",
    "    img = cv2.resize(img, (473, 473))\n",
    "    lab_media = cv2.resize(lab_media, (473, 473))\n",
    "    lab_lumen = cv2.resize(lab_lumen, (473, 473))\n",
    "    lab_media = np.where((lab_media == 1) | (lab_media == 255), lab_media, 0)\n",
    "    lab_lumen = np.where((lab_lumen == 1) | (lab_lumen == 255), lab_lumen, 0)\n",
    "    \n",
    "    # Use the model transforms\n",
    "    _  , lab_media = val_transform(img, lab_media)\n",
    "    img, lab_lumen = val_transform(img, lab_lumen)\n",
    "\n",
    "    return img.numpy(), lab_media.numpy(), lab_lumen.numpy()\n",
    "\n",
    "def load_data(location='../dataset/Data_set_B', batch=None, batchsize=10):\n",
    "\n",
    "    import os\n",
    "    import gc\n",
    "    from pathlib import Path\n",
    "    LOCATION = Path(location)\n",
    "\n",
    "    lum_files = sorted([f for f in os.listdir(LOCATION / 'LABELS_obs2_v2/') if 'lum' in f])\n",
    "    med_files = sorted([f for f in os.listdir(LOCATION / 'LABELS_obs2_v2/') if 'med' in f])\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache() # just in case\n",
    "    images = []\n",
    "    medias = []\n",
    "    lumens = []\n",
    "    for i, (luf, mef) in enumerate(zip(lum_files, med_files)):\n",
    "        if batch is not None:\n",
    "            if i < batch * batchsize:\n",
    "                continue\n",
    "            if i >= (batch + 1) * batchsize:\n",
    "                break\n",
    "        assert luf[3:] == mef[3:], (luf, mef)\n",
    "        _, _, patient, frame, _ = luf.split('_')\n",
    "        imf = LOCATION/ f'DCM/frame_{patient}_{frame}_003.png'\n",
    "        luf = os.path.join(LOCATION / 'LABELS_obs2_v2/', luf)\n",
    "        mef = os.path.join(LOCATION / 'LABELS_obs2_v2/', mef)\n",
    "        imf, luf, mef = map(str, [imf, luf, mef])\n",
    "        assert os.path.exists(imf), imf\n",
    "        img, med, lum = fetch_ivus_triplet(imf, mef, luf)\n",
    "        images.append(img)\n",
    "        medias.append(med)\n",
    "        lumens.append(lum)\n",
    "    images = np.stack(images)\n",
    "    medias = np.stack(medias)\n",
    "    medias = np.where(medias == 1, 2, medias)\n",
    "    lumens = np.stack(lumens)\n",
    "    torch.cuda.empty_cache()\n",
    "    return images, medias, lumens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b1479f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.PFENet import PFENet\n",
    "import torch\n",
    "from torch import nn\n",
    "SHOT = 1\n",
    "def get_model(shot, checkpoint='exp/ivus/split0_resnet50/model/final.pth'):\n",
    "    torch.cuda.empty_cache()\n",
    "    model = PFENet(layers=50, classes=2, zoom_factor=8, \\\n",
    "        criterion=nn.CrossEntropyLoss(ignore_index=255), BatchNorm=nn.BatchNorm2d, \\\n",
    "        pretrained=True, shot=shot, ppm_scales=[60, 30, 15, 8])\n",
    "\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model = torch.nn.DataParallel(model.cuda())\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.train(mode=False)\n",
    "    print('Allocated:', torch.cuda.memory_allocated())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f365d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show3(x, y, p, imshowargs=None, **kwargs):\n",
    "    _imshowargs = dict(cmap='gray')\n",
    "    if imshowargs:\n",
    "        _imshowargs.update(imshowargs)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, **kwargs)\n",
    "    \n",
    "    for a in ax:\n",
    "        a.set_yticks([])\n",
    "        a.set_xticks([])\n",
    "    \n",
    "    ax[0].set_title('Query')\n",
    "    ax[0].imshow(x, **_imshowargs)\n",
    "    \n",
    "    ax[1].set_title('Target')\n",
    "    ax[1].imshow(y, **_imshowargs)\n",
    "    \n",
    "    ax[2].set_title('Prediction')\n",
    "    ax[2].imshow(p, **_imshowargs)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ce7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OUTDIR = 'predictions'\n",
    "os.makedirs(OUTDIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d1fef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 30, 15, 8]\n",
      "INFO: Using ResNet 50\n",
      "Allocated: 327864832\n"
     ]
    }
   ],
   "source": [
    "images, medias, lumens = load_data()\n",
    "#torch.device('cpu')\n",
    "model = get_model(shot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a6d11",
   "metadata": {},
   "source": [
    "**Warning!** The following cells are very resource intensive, if you dont have a *huge* graphics card it will probably crash. Consider splitting the training in sub-datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b242c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(images[:, ...])\n",
    "y = torch.tensor(medias[:, ...])\n",
    "s_x = torch.tile(torch.tensor(images[:1, ...]), (len(x), 1, 1, 1, 1))\n",
    "s_y = torch.tile(torch.tensor(medias[:1, ...]), (len(x), 1, 1, 1))\n",
    "\n",
    "output1 = model(x=x, s_x=s_x, s_y=s_y).cpu().detach().numpy()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88dc209",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4250/4181652244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'lumen-{num}.png'\u001b[0m \u001b[0;31m# we start at the 1st image and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(output.argmax(1)):\n",
    "    num = str(i + n).zfill(4)\n",
    "    labname = f'lumen-{num}.png' # we start at the 1st image and\n",
    "    print('Saving', labname)\n",
    "    plt.imshow(p)\n",
    "    plt.show()\n",
    "    #assert cv2.imwrite(os.path.join(OUTDIR, labname), p)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
